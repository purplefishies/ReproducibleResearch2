---
title: "Investigating the patterns of damage from atmospheric natural disasters"
author: "Jimi Damon"
date: "06/21/2015"
output: pdf_document
hitheme: tomorrow
mode: selfcontained
highlighter: highlight.js
framework: io2012
url:
  assets: ../../assets
  lib: ../../librariesNew
widgets: mathjax
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='./figure/',
                     warning=FALSE, message=FALSE)
```

## Synopsis 

With global scientific consensus corroborating the direct
causal relationship between mankind's consumption of fossil fuels and
global climate change, it is increasingly important that government
agencies be aware of the variety and scale of these events so that
contingency and budgetary plans can be constructed to most effectively
handle these events when they occur.  In addition to planning for
future events, it is important that historical data be preserved for
use in categorizing and comparing new storm events to events measured
during times of lower $CO_2$ concentrations.

In this analysis, I investigated ways to assess which weather related
events, as provided by the U.S. National Oceanic and Atmospheric
Administration's (NOAA) storm database between the years of 1950 and
2011, provide the most harm to both Human life and to the economy
based on two key economic metrics. I performed some complex filtering
which allowed me to identify the top two types of disasters that
affect human life accross the the statistics of average fatalities and
injuries as well as economic health in terms of average property and crop
damage. The assumptions for this analysis were built up on the
analysis that Earth's significant meteorological and geological events
of the last 60 years were can represent the long term average for the
foreseeable future.

## Set up

In order to assist with the analysis of a large data set, I have
created two data sets : one represents the full NOAA set of
data, and the other contains a smaller subset of the full set of
data. In order select one data set or the other a "symbolic link" is
setup from the file "stormdata.csv" to point to the data set in
question. 

This approach makes it much easier to regenerate this document for the
full set of data after spending time working and debugging the
analysis while working on the much smaller set of data.  The
metaphorical "switch" can be flipped by just removing the file
"stormdata.csv" and then re-linking it to the large CSV file.

---

## Data Processing

### R Libraries used for this analysis
```{r,echo=TRUE,results='asis'}
library(dplyr)
library(ggplot2)
library(lubridate)
```

### Reading in the datasets

As mentioned in the Set up Section, the NOAA database was saved to the
file stormdata.csv. I began my analysis by reading this file in.

```{r,echo=TRUE,cache=TRUE,results='asis'}
dat <- read.csv("./stormdata.csv")
ddat <- tbl_df( dat )
```


### Defining capture statistics

In order to keep a modular design to this project, I realized at first
that I wasn't sure of the statistics I wanted to keep as I built up my dataset.
Hence I used a generic function "capture_stats", that would be used to 
extract the relevant statistics from each captured sub grouping of the 
over all weather data. This function could easily extended to extract new statistics 
from the original stormdata.csv data set.

```{r,echo=TRUE}
capture_stats <- function() {
    setNames(list(~mean(FATALITIES,rm.na=TRUE),
                  ~mean(INJURIES,rm.na=TRUE),
                  ~mean(PROPDMG,rm.na=TRUE),
                  ~mean(CROPDMG,rm.na=TRUE),
                  ~n()
                  ),
             c("ave_fatalities","ave_injuries","ave_propdmg","ave_cropdmg","nevents")
             )  
}
```

### Filtering of the dataset 

I needed to get my data into a format that avoided redundancy and
over counting. I decided to group the types of weather related disasters
according to the following rules.

* Tornadoes according to the Fujita scale (F-scale) 0,1,2,3,4,5
* Hurricanes that do not involve tornadoes or hail
* Hail of any type that do not include tornadoes
* Thunderstorm / High Wind related but no tornadoes, hurricanes or hail related
* Cold without snow and ice related injuries and deaths
* Heat (without dust)
* Flood 
* Ice and Snow but discounting cold related effects
* Volcanoes
* Dust without heat 

The process for creating the filters was performed in an iterative
way so as to ensure that data wasn't counted twice to a given
category. The first few data types were easier such as tornadoes and hurricanes
as the selection of these events amounted to filtering for these
categories. As I continued with this analysis of these events, it
became difficult to filter out events that were already counted. For
instance, when drilling down into a more selective category like hail, it was
important to perform appropriate filters that would select out
categories that were already counted: namely the categories tornadoes and
hurricanes would be over counted unless appropriate filters were used
to remove the intersection of hail and tornadoes events as well as the intersection
of hail and hurricane events.

#### Design of the filters.

Filters were design in a bottom up format whereby new filters were
designed by creating a filter and iteratively verifying that it's
selection of events did not intersect with any previously created
filter. This trial and error process , while complex, did ensure that
events were not doubly counted.

```{r,echo=TRUE}
tornado_filter <- ~!is.na(F)
hurricane_filter <- ~grepl(".*hur[r]?i.*", EVTYPE,perl=T,ignore.case=T )
hail_filter <- ~grepl(".*hail.*", EVTYPE,perl=T,ignore.case=T) & !grepl(".*tornado.*",  EVTYPE,perl=T,ignore.case=T)
wind_tstorm_filter <- ~grepl(".*(wind|thunder|tstm).*", EVTYPE,perl=T,ignore.case=T) &
    !grepl(".*tornado.*",  EVTYPE,perl=T,ignore.case=T) & 
    !grepl(".*hurricane.*",  EVTYPE,perl=T,ignore.case=T) &
    !grepl(".*(cold|chill).*",  EVTYPE,perl=T,ignore.case=T) &
    !grepl(".*(flood).*",  EVTYPE,perl=T,ignore.case=T)

cold_noicesnow_filter <- ~grepl(".*(cold|chill).*", EVTYPE,perl=T,ignore.case=T) &
    !grepl(".*(flood).*",  EVTYPE,perl=T,ignore.case=T) &
    !grepl(".*(snow|ice).*", EVTYPE,perl=T,ignore.case=T)

icesnow_filter <- ~grepl(".*(ice|snow).*", EVTYPE,perl=T,ignore.case=T) & 
  !grepl(".*(flood).*",  EVTYPE,perl=T,ignore.case=T) &
	!grepl(".*(chill|snow).*",EVTYPE,perl=T,ignore.case=T) &
	!grepl(".*(wind).*",EVTYPE,perl=T,ignore.case=T)

head_filter <- ~grepl(".*(heat).*", EVTYPE,perl=T,ignore.case=T)

flood_filter <- ~grepl(".*(flood).*", EVTYPE,perl=T,ignore.case=T) &
    !grepl(".*(thunder|tstm).*",  EVTYPE,perl=T,ignore.case=T) & 
    !grepl(".*(wind).*",  EVTYPE,perl=T,ignore.case=T) & 
    !grepl(".*(snow).*",  EVTYPE,perl=T,ignore.case=T) 

volcano_filter <- ~grepl(".*volc.*", EVTYPE,perl=T,ignore.case=T)

dust_filter <- ~grepl(".*dust.*", EVTYPE,perl=T,ignore.case=T) &
    !grepl(".*(wind).*",EVTYPE,perl=T,ignore.case=T)
```

---
### Example Sub-tables created by filters
#### Tornadoes

```{r,echo=TRUE}
tornadoes <- ddat %>%
    filter_( .dots=tornado_filter ) %>%
    group_by(F) %>%
    mutate( EVTYPE=ifelse(!is.na(F),paste("TORNADO_F",as.character(F),sep=""),"BLAH"))  %>%
    group_by( EVTYPE ) %>% 
    summarise_( .dots=capture_stats() )
```

#### Example of Tornadoe Human and Property Damage
```{r,echo=FALSE}
knitr::kable(tornadoes)
```


### Hurricanes

```{r,echo=TRUE,}
hurricane <- ddat %>%
    filter_( .dots=hurricane_filter ) %>%
    mutate( EVTYPE="HURRICANE") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )
```

### Hail only effects

```{r,echo=TRUE}
hail <- ddat %>%
    filter_( .dots=hail_filter ) %>%
    mutate( EVTYPE="HAIL") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )
```

### Thunderstorm and Wind

```{r,echo=TRUE}
wind_tstorm <- ddat %>%
    filter_( .dots=wind_tstorm_filter ) %>%
    mutate( EVTYPE="WIND_OR_TSTM") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )
```

### Cold Without Snow or Ice

```{r,echo=TRUE}
cold_noicesnow <- ddat %>%
    filter_( .dots=cold_noicesnow_filter ) %>%
    mutate( EVTYPE="COLD") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )
```

### Heat 

```{r,echo=TRUE}
heat <- ddat %>%
    filter_( .dots=head_filter ) %>%
    mutate( EVTYPE="HEAT") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )

```

### Flood

```{r,echo=TRUE}
flood <- ddat %>%
    filter_( .dots=flood_filter ) %>%
    mutate( EVTYPE="FLOOD") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )

```

### Ice and Snow without wind effects

```{r,echo=TRUE}
icesnow <- ddat %>%
    filter_( .dots=icesnow_filter ) %>%
    mutate( EVTYPE="ICE_SNOW") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )
```

### Volcano related 

```{r,echo=TRUE}
volcano <- ddat %>%
    filter_( .dots=volcano_filter ) %>% 
    mutate( EVTYPE="VOLCANO") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )
```

### Dust related

```{r,echo=TRUE}
dust <- ddat %>%
    filter_( .dots=dust_filter ) %>% 
    mutate( EVTYPE="DUST") %>%
    group_by(EVTYPE) %>%
    summarise_( .dots=capture_stats() )
```

### Combined table

After each factor is isolated, I combine each of these sub-tables into
a master table to consolidate results and make it easier to work on
the aggregate levels.


```{r,echo=TRUE}
all_data <- Reduce( function(x,y){ merge(x,y,all=T) }, 
            list(tornadoes, hurricane, 
                 hail, wind_tstorm, 
                 cold_noicesnow, heat, 
                 flood, icesnow, 
                 volcano, dust ) )
```
```{r,echo=FALSE}
knitr::kable( all_data %>% arrange( desc(ave_fatalities), desc(ave_injuries)))
```

## Results

To fully analyze this data set I decided to only take the
top weather related disasters that were considered leaders of the statistics fatalities,
injuries, property and crop damage.  


```{r,echo=FALSE}
knitr::kable( all_data %>% mutate ( expfatal=ave_fatalities * nevents / 60 ) %>% arrange( desc(expfatal)))
```                  

<!-- asdpp  -->
```{r,echo=TRUE}
topinjure  <- all_data %>% transmute( EVTYPE,exp_injure=(nevents/60)*ave_injuries) %>% arrange(desc(exp_injure))  %>% top_n(1) %>% transmute(EVTYPE)
topdmg     <- all_data %>% transmute( EVTYPE,exp_dmg=(nevents/60)*ave_propdmg) %>% arrange(desc(exp_dmg))         %>% top_n(1) %>% transmute(EVTYPE)
topcrop    <- all_data %>% transmute( EVTYPE,exp_cropdmg=(nevents/60)*ave_cropdmg) %>% arrange(desc(exp_cropdmg)) %>% top_n(1) %>% transmute(EVTYPE)
topfatal   <- all_data %>% transmute( EVTYPE,exp_fatal=(nevents/60)*ave_fatalities) %>% arrange(desc(exp_fatal))  %>% top_n(1) %>% transmute(EVTYPE)
all_top <- tbl_df(all_data[all_data$EVTYPE %in% c(topinjure,topdmg,topcrop,topfatal),])
knitr::kable( all_top )
```

and a final transformation

```{r,echo=TRUE}
xform_expected <- function() {
    setNames(list(~EVTYPE,
                  ~((nevents/60)*ave_fatalities),
                  ~((nevents/60)*ave_injuries),
                  ~((nevents/60)*ave_propdmg),
                  ~((nevents/60)*ave_cropdmg),
                  ~nevents
                  ),
             c("EVTYPE","exp_fatalities","exp_injuries","exp_propdmg","exp_cropdmg","nevents")
             )
}
ntable <- all_top %>% transmute_(.dots = xform_expected() )
knitr::kable( ntable  )
```

